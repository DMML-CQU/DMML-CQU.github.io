---
layout: post
title:  "A Snapshot of the Frontiers of Fairness in Machine Learning"
author: jane
categories: [ paper-recommendation, perspective ]
image: assets/images/fairness-ai.jpg
---

The last decade has seen a vast increase both in the diversity of applications to which machine learning is applied, and to the import of those applications. Machine learning is no longer just the engine behind ad placements and spam filters; it is now used to filter loan applicants, deploy police officers, and inform
bail and parole decisions, among other things. The result has been a major concern for the potential for data-driven methods to introduce and perpetuate discriminatory practices, and to otherwise be unfair. And this concern has not been without reason: a steady stream of empirical findings has shown that data-driven methods can unintentionally both encode existing human biases and introduce new ones.

Authors: Alexandra Chouldechova , Aaron Roth

Journal: Communications of the ACM

[Paper Download](https://dl.acm.org/doi/abs/10.1145/3376898)